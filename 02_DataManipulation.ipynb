
"cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buP_IK9cq4Gx"
   },
   "source": [
    "Note: All code in script is sourced from various internet sources, from mentor Tomasz Popiel and from Alan Chalk at Sabre Insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation\n",
    "\n",
    "Contents:\n",
    "\n",
    " - Start_: import modules, set directories, load data ('01_df_all.pickle')\n",
    " \n",
    " - Omit the identical and all 0 columns\n",
    " \n",
    " - Deal with missing values \n",
    " \n",
    " - One hot encoding categorical varaibles\n",
    " \n",
    " - Deal with hccv's\n",
    " \n",
    " - Defining varaibles and save clean data ('02_df_all.pickle')\n",
    "\n",
    "Notes:\n",
    " - remove 144 records where a_v6 is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start_:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hujuiting/Desktop/QM-BA/GROUP PROJECT/PCode\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "dirRawData = \"../RawData/\"\n",
    "dirPData = \"../PData/\"\n",
    "dirPOutput = \"../POutput/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65340, 347)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = dirPData + '01_df_all.pickle'\n",
    "with open(fname, 'rb') as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "\n",
    "# %% Load data\n",
    "\n",
    "df_all = dict_['df_all']\n",
    "del fname\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omit variables\n",
    "\n",
    "Omit duplicate varaibles and varaibles with all values 0\n",
    "\n",
    " - tq_db_26 is duplicate of tq_db_25    \n",
    " - tq_db_44 is duplicate of tq_db_43    \n",
    " - tq_db33_13 and tq_db34_13 values are all 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['tq_db26_1','tq_db26_2','tq_db33_13','tq_db34_13','tq_db44_1','tq_db44_2','tq_db44_3'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Deal with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tq_v3_mean          1\n",
       "tq_db11_std      3693\n",
       "tq_db12_std      3693\n",
       "tq_db13_std      3693\n",
       "tq_db14_std      3693\n",
       "tq_dt1_std       3693\n",
       "tq_dt2_std       3693\n",
       "tq_dt3_std       3693\n",
       "tq_dt4_std       3693\n",
       "tq_db15_std      3693\n",
       "tq_db16_std      3693\n",
       "tq_db17_std      3693\n",
       "tq_db18_std      3693\n",
       "tq_db19_std      3693\n",
       "tq_db20_std      3693\n",
       "tq_db21_std      3693\n",
       "tq_db22_std      3693\n",
       "tq_db23_std      3693\n",
       "tq_v3_std        3693\n",
       "tq_da1_Mean       370\n",
       "tq_db4_Mean       366\n",
       "tq_db5_Mean       366\n",
       "tq_db6_Mean       366\n",
       "tq_db7_Mean       366\n",
       "tq_db8_Mean       365\n",
       "tq_db9_Mean       365\n",
       "tq_db10_Mean     3503\n",
       "tq_v2_Mean         13\n",
       "tq_da1_Mode      6980\n",
       "tq_db1_Mode      4148\n",
       "                ...  \n",
       "tq_db46_17      65339\n",
       "tq_db47_2        6584\n",
       "tq_db47_3       12819\n",
       "tq_db47_4       19345\n",
       "tq_db47_5       26138\n",
       "tq_db47_6       33333\n",
       "tq_db47_7       41953\n",
       "tq_db47_8       52425\n",
       "tq_db47_9       61329\n",
       "tq_db47_10      65334\n",
       "tq_db48_2        6379\n",
       "tq_db48_3       12246\n",
       "tq_db48_4       18003\n",
       "tq_db48_5       24196\n",
       "tq_db48_6       31154\n",
       "tq_db48_7       40492\n",
       "tq_db48_8       51489\n",
       "tq_db48_9       60907\n",
       "tq_db48_10      65335\n",
       "tq_db49_2       27020\n",
       "tq_db49_3       60220\n",
       "tq_db49_4       64749\n",
       "tq_db50_2       28562\n",
       "tq_db50_3       60577\n",
       "tq_db50_4       64804\n",
       "a_v6              144\n",
       "a_v9              365\n",
       "a_v10           12827\n",
       "a_v11            4384\n",
       "a_v12           12838\n",
       "Length: 247, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs_nulls = df_all.isnull().sum()\n",
    "srs_nulls[srs_nulls > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a_v6 is missing because they were included in error and they are not real objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65340, 340)\n",
      "(65196, 340)\n"
     ]
    }
   ],
   "source": [
    "# note from AC: a_v6 is missing because they were included in error and they are not real objects\n",
    "# hence delete lines where a_v6 is missing\n",
    "# we should see shape reduce by 144\n",
    "print(df_all.shape) #65,340\n",
    "df_all.dropna(axis=0, subset=['a_v6'], inplace=True)\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "print(df_all.shape) #65,196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with histogram varaibles missing values \n",
    "\n",
    "- Replace missing values in histogram varaibles with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_hist_prefix = ('tq_db24', 'tq_db25', 'tq_db27', 'tq_db28', 'tq_db29', 'tq_db30','tq_db31',\n",
    "                           'tq_v4', 'tq_v5', 'tq_db32', 'tq_db33', 'tq_db34', \n",
    "                           'tq_da12','tq_da13', 'tq_da14',\n",
    "                           'tq_db35', 'tq_db36','tq_db37', 'tq_db38',\n",
    "                           'tq_db39', 'tq_db40', 'tq_db41', 'tq_db42',\n",
    "                           'tq_db43', 'tq_db45', 'tq_db46',\n",
    "                           'tq_db47', 'tq_db48', 'tq_db49', 'tq_db50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_hist = [col for col in df_all.columns if col.startswith(vars_hist_prefix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in vars_hist:\n",
    "    df_all[column].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with numerical variables missing values \n",
    "\n",
    "- Replace missing values in numerical varaibles with mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_numeric = [var for var in df_all.columns if var.endswith(('_mean', '_std', '_Mean', '_Mode', '_StdDev','_NMiss'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in vars_numeric:\n",
    "    df_all[column].fillna((df_all[column].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['a_v6', 'a_v9', 'a_v10', 'a_v11', 'a_v12']:\n",
    "    \n",
    "    df_all[col].fillna((df_all[col].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding categorical varaibles\n",
    "One hot encoding for categorical varaibles: a_v1, a_v2, a_v3, a_v4, a_v5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['a_v1', 'a_v2', 'a_v3', 'a_v4', 'a_v5']:\n",
    "    df_onehot = pd.get_dummies(df_all[var], prefix = var + '_') \n",
    "    df_all = df_all.join(df_onehot)\n",
    "    df_all.drop([var], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with hccv's \n",
    "\n",
    "a_v7 and a_v8 are hccv's (a_v8 is a lower hierarchy under a_v7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate a_v7 and a_v8, creating new variable a_v7_8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['a_v7_8'] = df_all['a_v7'].map(str) + '_' + df_all['a_v8'].map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of each category in new varaible a_v7_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_all['a_v7_8'].value_counts()\n",
    "\n",
    "# Make the counts a data frame df2\n",
    "df2 = pd.DataFrame(data=df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the cumulative percentage of each category in new varaible a_v7_8\n",
    "df2['Cumulative_Percentage'] = 100*df2.a_v7_8.cumsum()/df2.a_v7_8.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "listing out all the catogories with freq <= 24\n",
    " - one hot the whole feature\n",
    " - sum the columns in the resulting matrix and keep only cols with sum >= 25\n",
    " - add one final column \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode new varaible a_v7_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â one hot the whole varaible a_v7_8\n",
    "df2 = pd.get_dummies(df_all['a_v7_8'], prefix = 'a_v7_8' + '_') \n",
    "\n",
    "# sum the varaibles in the resulting matrix\n",
    "df2_freq = df2.sum(axis=0)\n",
    "\n",
    "# keep only varaibles with frequency <= 24\n",
    "idx_freq = df2_freq.values >= 25\n",
    "df2 = df2.iloc[:, idx_freq]\n",
    "\n",
    "# add varaible \"other\"\n",
    "df2['a_v7_8_other'] = 1 - df2.sum(axis=1)\n",
    "\n",
    "df_all = df_all.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop variables a_v7_8, av7 and av8\n",
    "df_all.drop(['a_v7_8'], axis=1, inplace=True)\n",
    "df_all.drop(['a_v7'], axis=1, inplace=True)\n",
    "df_all.drop(['a_v8'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65196, 643)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining variables and save clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining category variables\n",
    "vars_cat = ('a_v1_', 'a_v2_', 'a_v3_', 'a_v4_', 'a_v5_','a_v7_8_')\n",
    "vars_cat = [col for col in df_all.columns if col.startswith(vars_cat)]\n",
    "\n",
    "# Defining target variables \n",
    "vars_target = ['tq_dt1_mean','tq_dt2_mean','tq_dt3_mean','tq_dt4_mean','tq_dt1_std','tq_dt2_std','tq_dt3_std','tq_dt4_std']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update df_all in dict_\n",
    "dict_['df_all'] = df_all\n",
    "\n",
    "# Target variables \n",
    "dict_['vars_target'] = vars_target\n",
    "\n",
    "# Category variables\n",
    "dict_['vars_cat'] = vars_cat\n",
    "\n",
    "# Histogram variables \n",
    "dict_['vars_hist'] = vars_hist\n",
    "\n",
    "# Numeric variables \n",
    "dict_['vars_numeric'] = vars_numeric + ['tq_v3','a_v6', 'a_v9', 'a_v10', 'a_v11', 'a_v12']\n",
    "\n",
    "\n",
    "fname = dirPData + '02_df_all.pickle'\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(dict_, f)\n",
    "\n",
    "del dict_, fname"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
